% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ds.vertGLM.R
\name{ds.vertGLM}
\alias{ds.vertGLM}
\title{Generalized Linear Model for Vertically Partitioned Data}
\usage{
ds.vertGLM(
  data_name,
  y_var,
  x_vars,
  y_server = NULL,
  family = "gaussian",
  max_iter = 100,
  tol = 1e-04,
  lambda = 1e-04,
  log_n = 12,
  log_scale = 40,
  verbose = TRUE,
  datasources = NULL
)
}
\arguments{
\item{data_name}{Character string. Name of the (aligned) data frame on
each server.}

\item{y_var}{Character string. Name of the response variable (must exist
on the label server specified by \code{y_server}).}

\item{x_vars}{A named list where each name corresponds to a server name
and each element is a character vector of predictor variable names
from that server.}

\item{y_server}{Character string. Name of the server holding the response
variable. This server uses plaintext IRLS; all other servers use the
encrypted gradient protocol.}

\item{family}{Character string. GLM family: "gaussian", "binomial",
or "poisson". Default is "gaussian".}

\item{max_iter}{Integer. Maximum number of BCD iterations. Default is 100.}

\item{tol}{Numeric. Convergence tolerance on coefficient change.
Default is 1e-4 (accounts for CKKS approximation noise).}

\item{lambda}{Numeric. L2 regularization parameter. Default is 1e-4.}

\item{log_n}{Integer. CKKS ring dimension parameter (12, 13, or 14).
Default is 12 (2048 slots, supports up to 2048 observations).}

\item{log_scale}{Integer. CKKS scale parameter. Default is 40.}

\item{verbose}{Logical. Print progress messages. Default is TRUE.}

\item{datasources}{DataSHIELD connection object or list of connections.
If NULL, uses all available connections.}
}
\value{
A list with class "ds.glm" containing:
\itemize{
\item \code{coefficients}: Named vector of coefficient estimates
(on original scale, including intercept)
\item \code{iterations}: Number of iterations until convergence
\item \code{converged}: Logical indicating convergence
\item \code{family}: Family used
\item \code{n_obs}: Number of observations
\item \code{n_vars}: Number of predictor variables (including intercept)
\item \code{lambda}: Regularization parameter used
\item \code{deviance}: Residual deviance of the fitted model
\item \code{null_deviance}: Null deviance (intercept-only model)
\item \code{pseudo_r2}: McFadden's pseudo R-squared
\item \code{aic}: Akaike Information Criterion
\item \code{y_server}: Name of the label server
\item \code{call}: The matched call
}
}
\description{
Client-side function that fits a Generalized Linear Model
across vertically partitioned data using Block Coordinate Descent with
encrypted labels. The response variable y only needs to exist on ONE
server (the "label server"). Non-label servers compute gradient updates
using y encrypted under the MHE collective public key, and only the
aggregated p_k-length gradient is revealed via threshold decryption.
}
\details{
\subsection{Feature Standardization}{
Features are automatically standardized (centered and scaled) on each
server before BCD to ensure fast convergence. For Gaussian family, the
response is also standardized. Coefficients are transformed back to the
original scale after convergence, and an intercept is computed.
}

\subsection{Encrypted-Label BCD-IRLS Protocol}{
The response variable y resides on a single "label server". Non-label
servers never see y in plaintext. The protocol proceeds as:

\enumerate{
\item \strong{MHE Key Setup}: All servers generate key shares and
combine them into a Collective Public Key (CPK) with Galois keys.
\item \strong{Standardize}: Each server standardizes its features.
\item \strong{Encrypt y}: The label server encrypts (standardized) y
under the CPK and distributes the ciphertext to non-label servers.
\item \strong{BCD Loop}: For each iteration, each server updates
its block of coefficients on the standardized scale.
\item \strong{Unstandardize}: Coefficients are transformed back to the
original scale and an intercept is computed.
\item \strong{Deviance}: Computed on the label server using
plaintext y and the final linear predictor (original scale).
}
}
}
\examples{
\dontrun{
x_vars <- list(
  server1 = c("age", "bmi"),
  server2 = c("glucose"),
  server3 = c("cholesterol", "heart_rate")
)

# Gaussian GLM (bp on server2)
model <- ds.vertGLM("D_aligned", "bp", x_vars,
                     y_server = "server2", family = "gaussian")
print(model)
}

}
\references{
van Kesteren, E.J. et al. (2019). Privacy-preserving generalized linear
models using distributed block coordinate descent. arXiv:1911.03183.

Mouchet, C. et al. (2021). "Multiparty Homomorphic Encryption from
Ring-Learning-With-Errors". \emph{Proceedings on Privacy Enhancing Technologies}.
}
\seealso{
\code{\link{ds.vertCor}} for correlation analysis,
\code{\link{ds.vertPCA}} for PCA analysis
}
