---
title: "Getting Started with dsVertClient"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with dsVertClient}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  message = FALSE,
  warning = FALSE,
  class.output = "bg-light",
  results = "hold"
)
```

## What is Vertical Data Partitioning?

In traditional **horizontal partitioning**, different institutions hold data for *different patients* with the *same variables*. For example, Hospital A has 1000 patients and Hospital B has 2000 different patients, but both measure the same things (age, blood pressure, etc.).

**Vertical partitioning** is different: multiple institutions hold data for the *same patients* but with *different variables*. This commonly occurs when:

- A hospital has clinical data (diagnoses, treatments)
- A laboratory has biomarker measurements
- A research center has genomic data
- A government agency has demographic data

All these institutions have records for the same individuals, identified by a common ID (e.g., national health number), but each holds different pieces of information.

### Example: Three Institutions with Shared Patients

```{r example-tables, echo=FALSE}
hospital_a <- data.frame(
  ID = c("P1", "P2", "P3"),
  Age = c(45, 52, 38),
  Weight = c(70, 85, 62)
)

lab_b <- data.frame(
  ID = c("P1", "P2", "P3"),
  Glucose = c(95, 110, 88),
  HDL = c(55, 42, 61)
)

research_c <- data.frame(
  ID = c("P1", "P2", "P3"),
  Gene1 = c(0.2, 0.5, 0.1),
  Gene2 = c(0.8, 0.3, 0.9)
)
```

<div style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: space-around;">
<div style="flex: 1; min-width: 150px;">
**Hospital A**

```{r hospital-table, echo=FALSE}
knitr::kable(hospital_a, align = "c")
```
</div>
<div style="flex: 1; min-width: 150px;">
**Laboratory B**

```{r lab-table, echo=FALSE}
knitr::kable(lab_b, align = "c")
```
</div>
<div style="flex: 1; min-width: 150px;">
**Research Center C**

```{r research-table, echo=FALSE}
knitr::kable(research_c, align = "c")
```
</div>
</div>

*Same patients (P1, P2, P3) but different variables at each institution.*

## The Privacy Challenge

To analyze relationships between variables held by different institutions (e.g., "Does glucose level correlate with genetic markers?"), traditionally you would need to:

1. Send all data to a central location
2. Merge the datasets
3. Perform the analysis

This approach has serious privacy and legal concerns:

- **Patient privacy**: Sensitive data leaves protected environments
- **Legal barriers**: GDPR and other regulations restrict data transfer
- **Trust issues**: Institutions may not trust each other with their data

## The DataSHIELD Solution

**DataSHIELD** is a framework that enables privacy-preserving federated analysis. The key principle is:

> *"Bring the analysis to the data, not the data to the analysis"*

Instead of moving data, DataSHIELD:

1. Sends analysis commands to each server
2. Each server executes computations locally on its data
3. Only **aggregate results** (never individual-level data) are returned
4. The client combines these aggregates to produce final results

**dsVertClient** extends DataSHIELD specifically for **vertically partitioned data**, implementing:

- Privacy-preserving record alignment via cryptographic hashing
- Distributed correlation and PCA using Block SVD
- Distributed GLM fitting using Block Coordinate Descent

---

## Our Test Environment

```{r setup-data, include=FALSE}
# Create test data silently (DSLite simulation)
library(DSLite)
library(dsVert)
library(dsVertClient)
library(DSI)

set.seed(2026)
n_patients <- 200

patient_ids <- paste0("PATIENT_", sprintf("%05d", 1:n_patients))

# Demographics
true_age <- round(rnorm(n_patients, mean = 55, sd = 12))
true_age <- pmax(18, pmin(true_age, 90))
true_weight <- round(rnorm(n_patients, mean = 75, sd = 15), 1)
true_weight <- pmax(45, true_weight)

# Clinical measurements
true_height <- round(rnorm(n_patients, mean = 170, sd = 10), 1)
true_bmi <- round(true_weight / (true_height/100)^2, 1)

# Lab results
true_glucose <- round(85 + 0.3 * true_age + 0.5 * true_bmi + rnorm(n_patients, 0, 15), 1)
true_cholesterol <- round(150 + 0.8 * true_age + 1.2 * true_bmi + rnorm(n_patients, 0, 30), 1)

# Outcomes
true_outcome_bp <- round(
  90 + 0.4 * true_age + 0.6 * true_bmi + 0.1 * true_glucose + rnorm(n_patients, 0, 8), 1
)
diabetes_logit <- -10 + 0.05 * true_age + 0.08 * true_bmi + 0.03 * true_glucose
true_outcome_diabetes <- rbinom(n_patients, 1, plogis(diabetes_logit))
visit_rate <- exp(-1 + 0.02 * true_age + 0.01 * true_bmi)
true_outcome_visits <- rpois(n_patients, pmin(visit_rate, 10))
true_outcome_cost <- round(exp(6 + 0.01 * true_age + 0.02 * true_bmi + rnorm(n_patients, 0, 0.5)), 2)

# Distribute to institutions with different orderings
order_A <- sample(n_patients)
order_B <- sample(n_patients)
order_C <- sample(n_patients)

institution_A <- data.frame(
  patient_id = patient_ids[order_A],
  age = true_age[order_A],
  weight = true_weight[order_A],
  outcome_bp = true_outcome_bp[order_A],
  outcome_diabetes = true_outcome_diabetes[order_A],
  outcome_visits = true_outcome_visits[order_A],
  outcome_cost = true_outcome_cost[order_A],
  stringsAsFactors = FALSE
)

institution_B <- data.frame(
  patient_id = patient_ids[order_B],
  height = true_height[order_B],
  bmi = true_bmi[order_B],
  outcome_bp = true_outcome_bp[order_B],
  outcome_diabetes = true_outcome_diabetes[order_B],
  outcome_visits = true_outcome_visits[order_B],
  outcome_cost = true_outcome_cost[order_B],
  stringsAsFactors = FALSE
)

institution_C <- data.frame(
  patient_id = patient_ids[order_C],
  glucose = true_glucose[order_C],
  cholesterol = true_cholesterol[order_C],
  outcome_bp = true_outcome_bp[order_C],
  outcome_diabetes = true_outcome_diabetes[order_C],
  outcome_visits = true_outcome_visits[order_C],
  outcome_cost = true_outcome_cost[order_C],
  stringsAsFactors = FALSE
)

# Setup DSLite server (simulates remote DataSHIELD servers)
dslite_server <- newDSLiteServer(
  tables = list(
    inst_A = institution_A,
    inst_B = institution_B,
    inst_C = institution_C
  )
)
dslite_server$config(defaultDSConfiguration(include = c("dsVert")))
assign("dslite_server", dslite_server, envir = globalenv())
```

For this tutorial, we have a simulated environment with **3 institutions** and **200 patients**. Each institution holds different variables for the same patients:

| Institution | Role | Variables |
|-------------|------|-----------|
| **inst_A** | Hospital | age, weight |
| **inst_B** | Clinic | height, bmi |
| **inst_C** | Laboratory | glucose, cholesterol |

All institutions also store outcome variables (blood pressure, diabetes status, hospital visits, costs) which will be used for GLM examples.

### Connecting to Servers

We connect to the DataSHIELD servers and assign the data to a symbol `D`:

```{r connect-servers}
# Build login credentials for each server
builder <- newDSLoginBuilder()
builder$append(server = "inst_A", url = "dslite_server",
               table = "inst_A", driver = "DSLiteDriver")
builder$append(server = "inst_B", url = "dslite_server",
               table = "inst_B", driver = "DSLiteDriver")
builder$append(server = "inst_C", url = "dslite_server",
               table = "inst_C", driver = "DSLiteDriver")

# Connect and assign data to symbol "D" on each server
connections <- datashield.login(builder$build(), assign = TRUE, symbol = "D")
```

### What Each Institution Sees

<div style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: space-around;">
<div style="flex: 1; min-width: 200px;">
**Institution A (Hospital)**

```{r show-inst-a, echo=FALSE}
knitr::kable(institution_A[1:5, c("patient_id", "age", "weight")], row.names = FALSE)
```
</div>
<div style="flex: 1; min-width: 200px;">
**Institution B (Clinic)**

```{r show-inst-b, echo=FALSE}
knitr::kable(institution_B[1:5, c("patient_id", "height", "bmi")], row.names = FALSE)
```
</div>
<div style="flex: 1; min-width: 200px;">
**Institution C (Laboratory)**

```{r show-inst-c, echo=FALSE}
knitr::kable(institution_C[1:5, c("patient_id", "glucose", "cholesterol")], row.names = FALSE)
```
</div>
</div>

Notice how:

- Each institution has **different variables**
- The **patient order is different** at each institution
- The same patient (e.g., PATIENT_00093) appears at different row positions

This is realistic: institutions store data independently and don't coordinate their internal ordering.

---

## Step 1: Validating Identifier Formats

Before aligning records, we verify that patient identifiers have consistent formats across all institutions. Common problems include:

- Different ID formats (e.g., "001" vs "1" vs "P001")
- Leading/trailing whitespace
- Missing values or duplicates

```{r validate-ids}
validation_result <- ds.validateIdFormat(
  data_name = "D",
  id_col = "patient_id",
  datasources = connections
)

validation_result
```

**What we're looking for:**

- **n_obs**: Same number of observations across all institutions
- **n_unique**: Should equal n_obs (no duplicates)
- **n_missing**: Should be 0
- **format_signature**: Should be identical across institutions

---

## Step 2: Privacy-Preserving Record Alignment

### The Problem

Even though all institutions have data for the same patients, the records are in different order. To analyze relationships across variables (e.g., correlation between age and glucose), we need corresponding records to be in the same position.

**But we cannot simply share patient IDs!** That would violate privacy.

### The Solution: Cryptographic Hashing

Instead of sharing actual IDs, we:

1. **Hash all IDs** using SHA-256 (a one-way cryptographic function)
2. **Share only the hashes** - these cannot be reversed to reveal original IDs
3. **Reorder records** at each institution to match a reference order

| Original ID | → | SHA-256 Hash |
|-------------|---|--------------|
| `PATIENT_00042` | → | `a7f3b9c2d8e1f4a5...` (64 hex chars) |

The hash is shared safely - the original ID cannot be recovered from it.

### Step 2a: Get Reference Hashes

First, we obtain hashed identifiers from one institution (which becomes our reference):

```{r get-hashes}
reference_hashes <- ds.hashId(
  data_name = "D",
  id_col = "patient_id",
  algo = "sha256",
  datasource = connections["inst_A"]
)
```

We retrieved `r reference_hashes$n` hashed identifiers.

### Step 2b: Align All Institutions

Now we send the reference hashes to all institutions. Each institution:

1. Computes hashes of its own IDs
2. Reorders its records to match the reference hash order
3. Removes any records not in the reference set

```{r align-records}
ds.alignRecords(
  data_name = "D",
  id_col = "patient_id",
  reference_hashes = reference_hashes$hashes,
  newobj = "D_aligned",
  datasources = connections
)
```

### Verifying Alignment

```{r verify-alignment}
alignment_counts <- sapply(names(connections), function(inst) {
  count_result <- DSI::datashield.aggregate(
    connections[inst],
    call("getObsCountDS", "D_aligned")
  )
  count_result[[1]]$n_obs
})

data.frame(Institution = names(alignment_counts), Records = alignment_counts, row.names = NULL)
```

All institutions now have:

- The **same number of records**
- Records in the **same order** (corresponding to the same patients)
- Ready for **cross-institutional analysis**

---

## Next Steps

Now that records are aligned, we can perform statistical analyses:

- [**Statistical Analysis**](b-statistical-analysis.html): Correlation, PCA, and GLMs
- [**Methodology**](c-methodology.html): Mathematical details behind the algorithms

```{r cleanup, include=FALSE}
datashield.logout(connections)
rm("dslite_server", envir = globalenv())
```
